{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirments\n",
    "# !pip install pandas numpy pandas_datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dateutil import relativedelta, rrule\n",
    "from datetime import datetime, date, timedelta\n",
    "import functools\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import pandas_datareader.data as web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "PATH_DATA = os.path.join(\n",
    "    \"data\"\n",
    ")\n",
    "PATH_EXPORTS = os.path.join(\n",
    "    \"exports\"\n",
    ")\n",
    "PATH_SOURCE_CSV = os.path.join(\n",
    "    PATH_DATA,\n",
    "    \"cleaned_data_export.csv\"\n",
    ")\n",
    "PATH_EXPORT_DAILY_RET = os.path.join(\n",
    "    PATH_EXPORTS,\n",
    "    \"daily_returns.csv\"\n",
    ")\n",
    "PATH_EXPORT_MONTHLY_RET = os.path.join(\n",
    "    PATH_EXPORTS,\n",
    "    \"monthly_returns.csv\"\n",
    ")\n",
    "PATH_EXPORT_FORMULATION_RET = os.path.join(\n",
    "    PATH_EXPORTS,\n",
    "    \"formulation_returns.csv\"\n",
    ")\n",
    "PATH_EXPORT_HOLDING_WINNERS = os.path.join(\n",
    "    PATH_EXPORTS,\n",
    "    \"holding_winners.csv\"\n",
    ")\n",
    "PATH_EXPORT_HOLDING_LOOSERS = os.path.join(\n",
    "    PATH_EXPORTS,\n",
    "    \"holding_loosers.csv\"\n",
    ")\n",
    "PATH_EXPORT_HOLDING_RET = os.path.join(\n",
    "    PATH_EXPORTS,\n",
    "    \"holding_return.csv\"\n",
    ")\n",
    "PATH_EXPORT_RANKS = os.path.join(\n",
    "    PATH_EXPORTS,\n",
    "    \"ranks.csv\"\n",
    ")\n",
    "\n",
    "# dates\n",
    "DATE_SIMULATION_START = datetime(1998, 1, 1)\n",
    "DATE_SIMULATION_END = datetime(1999, 12, 1)\n",
    "DATE_CORONA = datetime(2020, 3, 1)\n",
    "WEIGHT_READJUST_DATES = [\n",
    "   DATE_CORONA\n",
    "]\n",
    "\n",
    "# const vars\n",
    "INTERVAL_FORMULATION = 12 # months\n",
    "INTERVAL_HOLDING = 3 # months\n",
    "TOP_N_PERCENT = 0.5\n",
    "BOTTOM_N_PERCENT = 0.5\n",
    "TICKER_FILTER_LIST = [\"CERG\", \"JEF\", \"ALJJ\", \"APF\", \"PIY\", \"KINS\", \"ROCM\", \"PETS\", \"HHY\", \"FFCO\"]\n",
    "ENABLE_TICKER_FILTER = True\n",
    "COLUMNS_MONTHLY_HOLDING_RETURNS = [\"year\", \"month\", \"winner_returns\", \"looser_returns\", \"winner_ticker\", \"looser_ticker\"]\n",
    "\n",
    "# init vars\n",
    "INIT_STOCK_SUMMARY = {\n",
    "    \"stock_count\": 0,\n",
    "    \"current_value\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_data(ticker, request_start_date, request_end_date, download=False):\n",
    "    # init df\n",
    "    res_df = None\n",
    "\n",
    "    # request datareader\n",
    "    try:\n",
    "        res_df = web.DataReader(ticker, 'yahoo', request_start_date, request_end_date)\n",
    "\n",
    "        #\n",
    "        if download:\n",
    "            res_df.to_csv(\"data/\" + ticker + \"-\" + str(request_start_date) + \"-\" + request_end_date + \".csv\", index=False)\n",
    "    except:\n",
    "        print(\"Error:\", ticker, request_start_date, request_end_date)\n",
    "\n",
    "    return res_df    \n",
    "\n",
    "def get_market_daily_closing(ticker, daily_date_start):\n",
    "    #\n",
    "    daily_returns = 0\n",
    "\n",
    "    #\n",
    "    daily_date_end = daily_date_start + timedelta(days=1)\n",
    "\n",
    "    # request data\n",
    "    market_daily_stats_df = request_data(ticker, daily_date_start, daily_date_end)\n",
    "\n",
    "    if market_daily_stats_df is not None:\n",
    "        # R(i,t)\n",
    "        daily_returns = 1 + (market_daily_stats_df['Close'] - market_daily_stats_df['Open'])\n",
    "    \n",
    "    #\n",
    "    return daily_returns\n",
    "\n",
    "def get_market_monthly_closing(ticker, start_date, end_date):\n",
    "    #\n",
    "    stock_returns_monthly = 0\n",
    "\n",
    "    for month_start_date in rrule.rrule(rrule.MONTHLY, dtstart=start_date, until=end_date):\n",
    "        #\n",
    "        month_end_date = month_start_date + relativedelta.relativedelta(months=1, day=1)\n",
    "\n",
    "        #\n",
    "        stock_returns_daily = 0\n",
    "        \n",
    "        for daily_date in rrule.rrule(rrule.DAILY, dtstart=month_start_date, until=month_end_date):\n",
    "            #\n",
    "            stock_returns_daily += get_market_daily_closing(ticker, daily_date)\n",
    "\n",
    "        #\n",
    "        stock_returns_monthly += stock_returns_daily\n",
    "\n",
    "        print(\"returns monthly:\" , stock_returns_monthly, \"\\n\")\n",
    "            \n",
    "# \n",
    "def get_market_stats_from_internet(ticker_list, start_date, end_date):\n",
    "    #\n",
    "    market_stats = dict()\n",
    "\n",
    "    #\n",
    "    for ticker in ticker_list:\n",
    "        #\n",
    "        get_market_monthly_closing(ticker, start_date, end_date)\n",
    "\n",
    "    return market_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path=PATH_SOURCE_CSV, rows=1000000):\n",
    "    if ENABLE_TICKER_FILTER:\n",
    "        return pd.read_csv(path, nrows=rows)    \n",
    "\n",
    "    return pd.read_csv(path)    \n",
    "\n",
    "def preprocess_data(data_df):\n",
    "    # format dt\n",
    "    data_df['date'] = pd.to_datetime(data_df['datadate'])\n",
    "\n",
    "    # sort\n",
    "    data_df.sort_values(by=['tic', 'date'], inplace=True)\n",
    "\n",
    "    # set index\n",
    "    # data_df.index = data_df['date']\n",
    "    \n",
    "    # extract month year\n",
    "    data_df['year'] = data_df['date'].dt.year\n",
    "    data_df['month'] = data_df['date'].dt.month\n",
    "    data_df['month_startdate'] = data_df['date'].to_numpy().astype('datetime64[M]')\n",
    "\n",
    "    # use fukter for debugging\n",
    "    if ENABLE_TICKER_FILTER:\n",
    "        data_df = data_df.loc[data_df['tic'].isin(TICKER_FILTER_LIST)]\n",
    "\n",
    "    return data_df   \n",
    "\n",
    "def init_stock_summary_dict(ticker):\n",
    "    return dict({ticker: INIT_STOCK_SUMMARY})\n",
    "# \n",
    "def get_portfolio_dict(market_revenue_stats):\n",
    "    #\n",
    "    stock_list = market_revenue_stats.tic.unique()\n",
    "\n",
    "    #\n",
    "    init_portfolio_dict = list(map(init_stock_summary_dict, stock_list))\n",
    "\n",
    "    return init_portfolio_dict, stock_list\n",
    "\n",
    "def get_iteration_intervals(start_date, end_date, interval_months=INTERVAL_FORMULATION):\n",
    "    #\n",
    "    intervals = []\n",
    "\n",
    "    #\n",
    "    interval_ticks = pd.date_range(start=start_date, end=end_date, freq=pd.offsets.MonthEnd(interval_months))\n",
    "\n",
    "    #\n",
    "    for idx, tick in enumerate(interval_ticks):\n",
    "        if idx > len(interval_ticks) - 2:\n",
    "            continue\n",
    "\n",
    "        intervals.append((\n",
    "            interval_ticks[idx],\n",
    "            interval_ticks[idx+1]   \n",
    "        ))\n",
    "\n",
    "    return intervals\n",
    "\n",
    "def get_aggregate_month_plus_one(revenues):    \n",
    "    revenue_pro = None\n",
    "    for revenue in revenues:\n",
    "        if revenue > 0:\n",
    "            if revenue_pro is None:\n",
    "                revenue_pro = (1 + revenue) \n",
    "            else:\n",
    "                revenue_pro *= (1 + revenue)\n",
    "\n",
    "    if revenue_pro is None:\n",
    "        return 0\n",
    "        \n",
    "    return revenue_pro - 1\n",
    "\n",
    "def get_aggregate_month(revenues):    \n",
    "    revenue_pro = None\n",
    "    for revenue in revenues:\n",
    "        if revenue > 0:\n",
    "            if revenue_pro is None:\n",
    "                revenue_pro = revenue\n",
    "            else:\n",
    "                revenue_pro *= revenue\n",
    "\n",
    "    if revenue_pro is None:\n",
    "        return 0\n",
    "        \n",
    "    return revenue_pro - 1\n",
    "\n",
    "def get_avg_portfolio_return(portfolio_returns):\n",
    "    return portfolio_returns.mean()\n",
    "\n",
    "def calculate_monthly_returns(raw_data_df):\n",
    "    processed_df = raw_data_df.copy()\n",
    "    processed_df[\"monthly_return\"] = raw_data_df.groupby([\"tic\", \"month_startdate\"]).daily_return.transform(get_aggregate_month)\n",
    "    processed_df = processed_df.drop_duplicates(subset=[\"tic\", 'month_startdate'])\n",
    "    # processed_df.index = processed_df[\"month_startdate\"]\n",
    "    \n",
    "    return processed_df\n",
    "\n",
    "def calculate_formulation_returns(raw_data_df):\n",
    "    processed_df = raw_data_df.copy()\n",
    "    formulation_returns = calculate_returns(processed_df, INTERVAL_FORMULATION,  \"tic\", \"monthly_return\", \"formulation_returns\")\n",
    "\n",
    "    return formulation_returns\n",
    "    \n",
    "def calculate_holding_returns(raw_data_df):\n",
    "    processed_df = raw_data_df.copy()\n",
    "    holding_returns = calculate_returns(processed_df, INTERVAL_HOLDING,  \"tic\", \"monthly_return\", \"holding_returns\")\n",
    "\n",
    "    return holding_returns\n",
    "\n",
    "def calculate_returns(raw_data_df, period, group_columns, apply_column, new_column_name):\n",
    "    monthly_grouped_df = raw_data_df.copy()\n",
    "    monthly_grouped_df[new_column_name] = monthly_grouped_df.groupby(group_columns)[apply_column].transform(lambda s: s.rolling(period).apply(get_aggregate_month_plus_one))\n",
    "\n",
    "    return monthly_grouped_df\n",
    "\n",
    "def calculate_avg_holding_returns(raw_data_df, period, group_columns, apply_column, new_column_name):\n",
    "    avg_holding_df = raw_data_df.copy()\n",
    "\n",
    "    avg_holding_df[new_column_name] = avg_holding_df.groupby(group_columns)[apply_column].transform(lambda s: s.rolling(period).apply(get_avg_portfolio_return))\n",
    "\n",
    "    print(\"calc\")\n",
    "    return avg_holding_df\n",
    "\n",
    "def get_holding_avg_returns(raw_data_df, tic_list, month_startdate):\n",
    "    processed_df = raw_data_df.copy()\n",
    "    year, month = month_startdate.year, month_startdate.month\n",
    "\n",
    "    # put tic, year, month filter\n",
    "    filtered_df = processed_df[(processed_df['month'] >= month) & (processed_df['month'] < month+INTERVAL_HOLDING) & (processed_df['year'] == year)]\n",
    "    filtered_df = filtered_df[filtered_df['tic'].isin(tic_list)] \n",
    "\n",
    "    #\n",
    "    holding_df = calculate_avg_holding_returns(filtered_df, INTERVAL_HOLDING,  \"tic\", \"monthly_return\", \"holding_returns\")\n",
    "\n",
    "    return holding_df.holding_returns.mean()\n",
    "\n",
    "def get_winner_looser_list(raw_data_df, month_startdate, winner_looser_type):\n",
    "    processed_df = raw_data_df.copy()\n",
    "    year, month = month_startdate.year, month_startdate.month\n",
    "    \n",
    "    #\n",
    "    filtered_df = processed_df[(processed_df['month'] == month) & (processed_df['year'] == year)]\n",
    "\n",
    "    #\n",
    "    tic_list = filtered_df[winner_looser_type]\n",
    "\n",
    "    if not tic_list.empty:\n",
    "        return tic_list.unique()[0].split(\",\")\n",
    "\n",
    "    return []\n",
    "\n",
    "#\n",
    "def check_weight_readjustment_date(budget_perc_1, budget_perc_2):\n",
    "    pass\n",
    "\n",
    "#\n",
    "def get_short_long_call(stock_stats_dict):\n",
    "    # if last 12 month max greater than current price, decide short or long\n",
    "    # get_market_stats()\n",
    "    pass\n",
    "\n",
    "def get_winner_losers(unlabelled_df, n_ranks, label):\n",
    "    # get\n",
    "    filtered_ranks = unlabelled_df.loc[unlabelled_df['compiled_rank'].isin(n_ranks)]\n",
    "    \n",
    "    return label\n",
    "\n",
    "def get_ranking_by_interval(raw_data_df):\n",
    "    processed_df = raw_data_df.copy()\n",
    "\n",
    "    # get ranks\n",
    "    processed_df[\"compiled_rank\"] = processed_df.groupby([\"month_startdate\"]).formulation_returns.transform(pd.DataFrame.rank, ascending=False)\n",
    "    processed_df = processed_df.sort_values([\"year\", \"month\", \"compiled_rank\"], ascending=True)\n",
    "\n",
    "    # drop nans\n",
    "    processed_df = processed_df[processed_df['compiled_rank'].notna()]\n",
    "\n",
    "    # get top and bottom n rank ranges\n",
    "    ranks_range = processed_df[\"compiled_rank\"].unique() \n",
    "    ranks_count = len(ranks_range)\n",
    "    top_n_ranks = ranks_range[:math.ceil(ranks_count * TOP_N_PERCENT)]\n",
    "    bottom_n_ranks = ranks_range[-math.ceil(ranks_count * BOTTOM_N_PERCENT):]\n",
    "    \n",
    "    # assign winner/looser label\n",
    "    processed_df.loc[processed_df.compiled_rank.isin(top_n_ranks), 'status'] = 'w'\n",
    "    processed_df.loc[processed_df.compiled_rank.isin(bottom_n_ranks), 'status'] = 'l'    \n",
    "\n",
    "    #\n",
    "    winner_df = processed_df.loc[processed_df['status'] == 'w']\n",
    "    winner_df[\"winners\"] = winner_df.groupby([\"month_startdate\"]).tic.transform(lambda x: \",\".join(x.astype(str)))\n",
    "    # winner_df = winner_df.drop_duplicates(subset=['month_startdate'])\n",
    "\n",
    "    looser_df = processed_df.loc[processed_df['status'] == 'l']\n",
    "    looser_df[\"loosers\"] = looser_df.groupby([\"month_startdate\"]).tic.transform(lambda x: \",\".join(x.astype(str)))\n",
    "    # looser_df = looser_df.drop_duplicates(subset=['month_startdate'])\n",
    "\n",
    "    return processed_df, winner_df, looser_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def run_simulation(start_date, end_date):\n",
    "    # read\n",
    "    data_df = read_data()\n",
    "\n",
    "    # preprocess data\n",
    "    data_df = preprocess_data(data_df)\n",
    "    data_df.to_csv(PATH_EXPORT_DAILY_RET)\n",
    "\n",
    "    # calculate monthly returns\n",
    "    monthly_df = calculate_monthly_returns(data_df)\n",
    "    monthly_df.to_csv(PATH_EXPORT_MONTHLY_RET)\n",
    "\n",
    "    # calculate formulation returns\n",
    "    formulation_df = calculate_formulation_returns(monthly_df)\n",
    "    formulation_df.to_csv(PATH_EXPORT_FORMULATION_RET)\n",
    "\n",
    "    # get ranking\n",
    "    ranked_df, winner_df, looser_df = get_ranking_by_interval(formulation_df)        \n",
    "    ranked_df.to_csv(PATH_EXPORT_RANKS)\n",
    "\n",
    "    # # calculate holding winning\n",
    "    # holding_df_winner = calculate_holding_returns(winner_df)\n",
    "    # holding_df_winner.rename(columns={\"holding_returns\": \"winning_returns\"}, inplace=True)\n",
    "    # holding_df_winner.to_csv(PATH_EXPORT_HOLDING_WINNERS)\n",
    "\n",
    "    # # calculate holding returns\n",
    "    # holding_df_looser = calculate_holding_returns(looser_df)\n",
    "    # holding_df_looser.rename(columns={\"holding_returns\": \"winning_returns\"}, inplace=True)    \n",
    "    # holding_df_looser.to_csv(PATH_EXPORT_HOLDING_LOOSERS)\n",
    "\n",
    "    # # #\n",
    "    # # combined_df = holding_df_winner.merge(holding_df_looser, on=\"month_startdate\", suffixes=(\"_winner\", \"_looser\"))\n",
    "    # # combined_df.to_csv(PATH_EXPORT_HOLDING_RET)\n",
    "\n",
    "    # for_formulation_ranking\n",
    "    iteration_intervals = get_iteration_intervals(start_date, end_date, 3)\n",
    "\n",
    "    # init dfs\n",
    "    monthly_holding_df = pd.DataFrame(columns=COLUMNS_MONTHLY_HOLDING_RETURNS)\n",
    "    yearly_holding_df = pd.DataFrame(columns=COLUMNS_MONTHLY_HOLDING_RETURNS)\n",
    "    \n",
    "    # iterate over 3 months\n",
    "    for interval_start, interval_end in iteration_intervals[:10000]:\n",
    "        # init vars\n",
    "        year, month = interval_start.year, interval_start.month\n",
    "        winner_returns = 0\n",
    "        looser_returns = 0\n",
    "\n",
    "        #\n",
    "        winners_list = get_winner_looser_list(winner_df, interval_start, \"winners\")\n",
    "\n",
    "        if len(winners_list) != 0:\n",
    "            winner_returns = get_holding_avg_returns(monthly_df, winners_list, interval_start)\n",
    "\n",
    "        #\n",
    "        loosers_list = get_winner_looser_list(looser_df, interval_start, \"loosers\")\n",
    "\n",
    "        if len(loosers_list) != 0:\n",
    "            looser_returns = get_holding_avg_returns(monthly_df, loosers_list, interval_start)\n",
    "\n",
    "        row_df = pd.DataFrame([[year, month, winner_returns, looser_returns, winners_list, loosers_list]], columns=COLUMNS_MONTHLY_HOLDING_RETURNS)\n",
    "\n",
    "        #\n",
    "        monthly_holding_df = pd.concat(\n",
    "            [monthly_holding_df, row_df],\n",
    "            ignore_index = True\n",
    "        )\n",
    "\n",
    "    #\n",
    "    monthly_holding_df.to_csv(PATH_EXPORT_HOLDING_RET)\n",
    "\n",
    "    # break\n",
    "    # update portfolio: stock-wise capital allocation\n",
    "    # print(rankings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calc\n",
      "calc\n",
      "calc\n",
      "calc\n",
      "calc\n",
      "calc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAWAI~1\\AppData\\Local\\Temp/ipykernel_8660/2570200036.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  winner_df[\"winners\"] = winner_df.groupby([\"month_startdate\"]).tic.transform(lambda x: \",\".join(x.astype(str)))\n",
      "C:\\Users\\SHAWAI~1\\AppData\\Local\\Temp/ipykernel_8660/2570200036.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  looser_df[\"loosers\"] = looser_df.groupby([\"month_startdate\"]).tic.transform(lambda x: \",\".join(x.astype(str)))\n"
     ]
    }
   ],
   "source": [
    "# run monthly simulation using market return stats\n",
    "run_simulation(DATE_SIMULATION_START, DATE_SIMULATION_END)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2c2515d1b2197254d1f64e5256eebba362f8280839ac2e0d007949d1be8cf8a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
